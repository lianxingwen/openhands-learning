"""
é¡¹ç›®2: LLMé›†æˆå®è·µ
å­¦ä¹ ç›®æ ‡: å­¦ä¹ å¦‚ä½•é›†æˆå¤§è¯­è¨€æ¨¡å‹APIï¼Œå®ç°çœŸæ­£çš„AIå¯¹è¯
éš¾åº¦: â­â­â­â˜†â˜†
"""

import asyncio
import json
import os
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
from abc import ABC, abstractmethod
import aiohttp
from datetime import datetime

@dataclass
class ChatMessage:
    """èŠå¤©æ¶ˆæ¯"""
    role: str  # 'system', 'user', 'assistant'
    content: str
    timestamp: Optional[str] = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now().isoformat()

class LLMProvider(ABC):
    """LLMæä¾›å•†æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    async def chat_completion(
        self, 
        messages: List[ChatMessage], 
        **kwargs
    ) -> Dict[str, Any]:
        pass

class OpenAIProvider(LLMProvider):
    """OpenAI APIæä¾›å•†"""
    
    def __init__(self, api_key: str, model: str = "gpt-3.5-turbo"):
        self.api_key = api_key
        self.model = model
        self.base_url = "https://api.openai.com/v1"
    
    async def chat_completion(
        self, 
        messages: List[ChatMessage], 
        temperature: float = 0.7,
        max_tokens: int = 1000,
        **kwargs
    ) -> Dict[str, Any]:
        """è°ƒç”¨OpenAI Chat Completion API"""
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        api_messages = [
            {"role": msg.role, "content": msg.content} 
            for msg in messages
        ]
        
        payload = {
            "model": self.model,
            "messages": api_messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            **kwargs
        }
        
        async with aiohttp.ClientSession() as session:
            try:
                async with session.post(
                    f"{self.base_url}/chat/completions",
                    headers=headers,
                    json=payload
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        return {
                            "success": True,
                            "content": result["choices"][0]["message"]["content"],
                            "usage": result.get("usage", {}),
                            "model": result.get("model", self.model)
                        }
                    else:
                        error_text = await response.text()
                        return {
                            "success": False,
                            "error": f"APIé”™è¯¯ {response.status}: {error_text}"
                        }
            except Exception as e:
                return {
                    "success": False,
                    "error": f"è¯·æ±‚å¼‚å¸¸: {str(e)}"
                }

class MockLLMProvider(LLMProvider):
    """æ¨¡æ‹ŸLLMæä¾›å•†ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    
    def __init__(self):
        self.responses = {
            "è®¡ç®—": "æˆ‘å¯ä»¥å¸®ä½ è¿›è¡Œæ•°å­¦è®¡ç®—ã€‚è¯·å‘Šè¯‰æˆ‘å…·ä½“çš„è®¡ç®—è¡¨è¾¾å¼ã€‚",
            "å¤©æ°”": "æˆ‘å¯ä»¥æŸ¥è¯¢å¤©æ°”ä¿¡æ¯ã€‚è¯·å‘Šè¯‰æˆ‘ä½ æƒ³æŸ¥è¯¢å“ªä¸ªåŸå¸‚çš„å¤©æ°”ã€‚",
            "ä½ å¥½": "ä½ å¥½ï¼æˆ‘æ˜¯AIåŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºä½ æœåŠ¡ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ",
            "è°¢è°¢": "ä¸å®¢æ°”ï¼å¦‚æœè¿˜æœ‰å…¶ä»–é—®é¢˜ï¼Œéšæ—¶å¯ä»¥é—®æˆ‘ã€‚"
        }
    
    async def chat_completion(
        self, 
        messages: List[ChatMessage], 
        **kwargs
    ) -> Dict[str, Any]:
        """æ¨¡æ‹ŸLLMå“åº”"""
        
        # æ¨¡æ‹ŸAPIå»¶è¿Ÿ
        await asyncio.sleep(0.5)
        
        if not messages:
            return {
                "success": False,
                "error": "æ²¡æœ‰æ¶ˆæ¯"
            }
        
        last_message = messages[-1].content.lower()
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        for keyword, response in self.responses.items():
            if keyword in last_message:
                return {
                    "success": True,
                    "content": response,
                    "usage": {"total_tokens": 50},
                    "model": "mock-llm"
                }
        
        # é»˜è®¤å“åº”
        return {
            "success": True,
            "content": "æˆ‘ç†è§£äº†ä½ çš„é—®é¢˜ã€‚è®©æˆ‘æƒ³æƒ³å¦‚ä½•æœ€å¥½åœ°å¸®åŠ©ä½ ...",
            "usage": {"total_tokens": 30},
            "model": "mock-llm"
        }

class FunctionTool:
    """å‡½æ•°å·¥å…·ç±»"""
    
    def __init__(self, name: str, description: str, parameters: Dict[str, Any], function):
        self.name = name
        self.description = description
        self.parameters = parameters
        self.function = function
    
    def to_openai_format(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºOpenAIå‡½æ•°è°ƒç”¨æ ¼å¼"""
        return {
            "type": "function",
            "function": {
                "name": self.name,
                "description": self.description,
                "parameters": self.parameters
            }
        }
    
    async def execute(self, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œå‡½æ•°"""
        try:
            if asyncio.iscoroutinefunction(self.function):
                result = await self.function(**kwargs)
            else:
                result = self.function(**kwargs)
            return {"success": True, "result": result}
        except Exception as e:
            return {"success": False, "error": str(e)}

class SmartAgent:
    """æ™ºèƒ½ä»£ç†ï¼ˆé›†æˆLLMï¼‰"""
    
    def __init__(self, llm_provider: LLMProvider, name: str = "SmartAgent"):
        self.llm_provider = llm_provider
        self.name = name
        self.conversation_history: List[ChatMessage] = []
        self.tools: Dict[str, FunctionTool] = {}
        self.system_prompt = """ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚ä½ å¯ä»¥ï¼š
1. å›ç­”å„ç§é—®é¢˜
2. è¿›è¡Œæ•°å­¦è®¡ç®—
3. æŸ¥è¯¢å¤©æ°”ä¿¡æ¯
4. æä¾›å»ºè®®å’Œå¸®åŠ©

è¯·æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›å¤ã€‚å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚"""
        
        # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
        self.add_message(ChatMessage(role="system", content=self.system_prompt))
    
    def add_tool(self, tool: FunctionTool):
        """æ·»åŠ å·¥å…·"""
        self.tools[tool.name] = tool
    
    def add_message(self, message: ChatMessage):
        """æ·»åŠ æ¶ˆæ¯"""
        self.conversation_history.append(message)
    
    async def chat(self, user_input: str) -> str:
        """ä¸ç”¨æˆ·å¯¹è¯"""
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        user_message = ChatMessage(role="user", content=user_input)
        self.add_message(user_message)
        
        # è·å–LLMå“åº”
        response = await self.llm_provider.chat_completion(
            messages=self.conversation_history,
            temperature=0.7
        )
        
        if response["success"]:
            assistant_content = response["content"]
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·
            tool_response = await self._check_and_use_tools(user_input, assistant_content)
            if tool_response:
                assistant_content = tool_response
            
            # æ·»åŠ åŠ©æ‰‹å›å¤
            assistant_message = ChatMessage(role="assistant", content=assistant_content)
            self.add_message(assistant_message)
            
            return assistant_content
        else:
            error_message = f"æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼š{response['error']}"
            assistant_message = ChatMessage(role="assistant", content=error_message)
            self.add_message(assistant_message)
            return error_message
    
    async def _check_and_use_tools(self, user_input: str, llm_response: str) -> Optional[str]:
        """æ£€æŸ¥å¹¶ä½¿ç”¨å·¥å…·"""
        user_input_lower = user_input.lower()
        
        # è®¡ç®—å·¥å…·
        if "calculator" in self.tools and any(
            keyword in user_input_lower 
            for keyword in ['è®¡ç®—', 'ç®—', '+', '-', '*', '/', 'ç­‰äº']
        ):
            # æå–æ•°å­¦è¡¨è¾¾å¼
            import re
            math_pattern = r'[\d+\-*/().\s]+'
            matches = re.findall(math_pattern, user_input)
            
            if matches:
                expression = max(matches, key=len).strip()
                result = await self.tools["calculator"].execute(expression=expression)
                
                if result["success"]:
                    return f"è®¡ç®—ç»“æœï¼š{expression} = {result['result']}"
                else:
                    return f"è®¡ç®—å‡ºé”™ï¼š{result['error']}"
        
        # å¤©æ°”å·¥å…·
        if "weather" in self.tools and any(
            keyword in user_input_lower 
            for keyword in ['å¤©æ°”', 'æ¸©åº¦', 'ä¸‹é›¨', 'æ™´å¤©']
        ):
            # æå–åŸå¸‚å
            cities = ["åŒ—äº¬", "ä¸Šæµ·", "æ·±åœ³", "å¹¿å·", "æ­å·"]
            city = None
            for c in cities:
                if c in user_input:
                    city = c
                    break
            
            if city:
                result = await self.tools["weather"].execute(city=city)
                
                if result["success"]:
                    weather = result["result"]
                    return f"{city}çš„å¤©æ°”ï¼š{weather}"
                else:
                    return f"æŸ¥è¯¢å¤±è´¥ï¼š{result['error']}"
        
        return None
    
    def get_conversation_summary(self) -> Dict[str, Any]:
        """è·å–å¯¹è¯æ‘˜è¦"""
        messages = [msg for msg in self.conversation_history if msg.role != "system"]
        return {
            "total_messages": len(messages),
            "user_messages": len([m for m in messages if m.role == "user"]),
            "assistant_messages": len([m for m in messages if m.role == "assistant"]),
            "conversation_start": messages[0].timestamp if messages else None,
            "conversation_end": messages[-1].timestamp if messages else None
        }
    
    def export_conversation(self, filename: str):
        """å¯¼å‡ºå¯¹è¯"""
        conversation_data = {
            "agent_name": self.name,
            "summary": self.get_conversation_summary(),
            "messages": [asdict(msg) for msg in self.conversation_history]
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(conversation_data, f, ensure_ascii=False, indent=2)

# å·¥å…·å‡½æ•°å®šä¹‰
def calculator_function(expression: str) -> str:
    """è®¡ç®—å™¨å‡½æ•°"""
    try:
        # å®‰å…¨è®¡ç®—
        allowed_chars = set('0123456789+-*/().')
        if not all(c in allowed_chars or c.isspace() for c in expression):
            raise ValueError("è¡¨è¾¾å¼åŒ…å«ä¸å…è®¸çš„å­—ç¬¦")
        
        result = eval(expression)
        return str(result)
    except Exception as e:
        raise ValueError(f"è®¡ç®—é”™è¯¯: {str(e)}")

async def weather_function(city: str) -> str:
    """å¤©æ°”æŸ¥è¯¢å‡½æ•°"""
    # æ¨¡æ‹Ÿå¤©æ°”æ•°æ®
    weather_data = {
        "åŒ—äº¬": "æ™´å¤©ï¼Œ22Â°Cï¼Œæ¹¿åº¦45%",
        "ä¸Šæµ·": "å¤šäº‘ï¼Œ25Â°Cï¼Œæ¹¿åº¦60%", 
        "æ·±åœ³": "å°é›¨ï¼Œ28Â°Cï¼Œæ¹¿åº¦75%",
        "å¹¿å·": "æ™´å¤©ï¼Œ30Â°Cï¼Œæ¹¿åº¦50%",
        "æ­å·": "å¤šäº‘ï¼Œ24Â°Cï¼Œæ¹¿åº¦55%"
    }
    
    if city in weather_data:
        return weather_data[city]
    else:
        raise ValueError(f"æœªæ‰¾åˆ°åŸå¸‚ {city} çš„å¤©æ°”ä¿¡æ¯")

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§  æ™ºèƒ½AIä»£ç†æ¼”ç¤ºï¼ˆLLMé›†æˆç‰ˆï¼‰")
    print("=" * 50)
    
    # é€‰æ‹©LLMæä¾›å•†
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        print("ğŸ”‘ ä½¿ç”¨OpenAI API")
        llm_provider = OpenAIProvider(api_key)
    else:
        print("ğŸ­ ä½¿ç”¨æ¨¡æ‹ŸLLMï¼ˆè®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡ä»¥ä½¿ç”¨çœŸå®APIï¼‰")
        llm_provider = MockLLMProvider()
    
    # åˆ›å»ºæ™ºèƒ½ä»£ç†
    agent = SmartAgent(llm_provider, "æ™ºèƒ½åŠ©æ‰‹")
    
    # æ·»åŠ å·¥å…·
    calculator_tool = FunctionTool(
        name="calculator",
        description="æ‰§è¡Œæ•°å­¦è®¡ç®—",
        parameters={
            "type": "object",
            "properties": {
                "expression": {
                    "type": "string",
                    "description": "æ•°å­¦è¡¨è¾¾å¼"
                }
            },
            "required": ["expression"]
        },
        function=calculator_function
    )
    
    weather_tool = FunctionTool(
        name="weather",
        description="æŸ¥è¯¢åŸå¸‚å¤©æ°”",
        parameters={
            "type": "object",
            "properties": {
                "city": {
                    "type": "string",
                    "description": "åŸå¸‚åç§°"
                }
            },
            "required": ["city"]
        },
        function=weather_function
    )
    
    agent.add_tool(calculator_tool)
    agent.add_tool(weather_tool)
    
    # æµ‹è¯•å¯¹è¯
    test_conversations = [
        "ä½ å¥½ï¼ä½ èƒ½åšä»€ä¹ˆï¼Ÿ",
        "å¸®æˆ‘è®¡ç®— 15 * 8 + 32",
        "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
        "è¯·è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½",
        "è®¡ç®— (100 - 25) / 5",
        "ä¸Šæµ·çš„å¤©æ°”å¦‚ä½•ï¼Ÿ",
        "è°¢è°¢ä½ çš„å¸®åŠ©ï¼"
    ]
    
    for user_input in test_conversations:
        print(f"\nğŸ‘¤ ç”¨æˆ·: {user_input}")
        response = await agent.chat(user_input)
        print(f"ğŸ¤– åŠ©æ‰‹: {response}")
        
        # æ·»åŠ å»¶è¿Ÿï¼Œæ¨¡æ‹ŸçœŸå®å¯¹è¯
        await asyncio.sleep(1)
    
    # æ˜¾ç¤ºå¯¹è¯æ‘˜è¦
    summary = agent.get_conversation_summary()
    print(f"\nğŸ“Š å¯¹è¯æ‘˜è¦:")
    print(f"   æ€»æ¶ˆæ¯æ•°: {summary['total_messages']}")
    print(f"   ç”¨æˆ·æ¶ˆæ¯: {summary['user_messages']}")
    print(f"   åŠ©æ‰‹å›å¤: {summary['assistant_messages']}")
    
    # å¯¼å‡ºå¯¹è¯
    agent.export_conversation("smart_conversation.json")
    print(f"\nğŸ’¾ å¯¹è¯å·²å¯¼å‡ºåˆ° smart_conversation.json")

if __name__ == "__main__":
    asyncio.run(main())

"""
ğŸ¯ å­¦ä¹ è¦ç‚¹:

1. **LLMé›†æˆ**: å­¦ä¹ å¦‚ä½•é›†æˆå¤§è¯­è¨€æ¨¡å‹API
   - APIè°ƒç”¨å°è£…
   - é”™è¯¯å¤„ç†
   - å¼‚æ­¥è¯·æ±‚

2. **æä¾›å•†æŠ½è±¡**: è®¾è®¡å¯æ‰©å±•çš„LLMæä¾›å•†ç³»ç»Ÿ
   - æŠ½è±¡åŸºç±»
   - å¤šç§å®ç°
   - ç»Ÿä¸€æ¥å£

3. **å·¥å…·ç³»ç»Ÿ**: å®ç°å‡½æ•°è°ƒç”¨å’Œå·¥å…·é›†æˆ
   - å·¥å…·å®šä¹‰
   - å‚æ•°éªŒè¯
   - ç»“æœå¤„ç†

4. **å¯¹è¯ç®¡ç†**: ç®¡ç†å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡
   - æ¶ˆæ¯å†å²
   - ä¸Šä¸‹æ–‡ä¿æŒ
   - å¯¹è¯å¯¼å‡º

ğŸ“ ç»ƒä¹ ä»»åŠ¡:

1. æ·»åŠ æ›´å¤šLLMæä¾›å•†ï¼ˆAnthropicã€Googleç­‰ï¼‰
2. å®ç°æµå¼å“åº”
3. æ·»åŠ å¯¹è¯è®°å¿†å‹ç¼©
4. å®ç°å·¥å…·é“¾è°ƒç”¨
5. æ·»åŠ å¯¹è¯è¯„ä¼°æŒ‡æ ‡

ğŸš€ æ‰©å±•æ–¹å‘:

1. å®ç°RAGç³»ç»Ÿ
2. æ·»åŠ å¤šæ¨¡æ€æ”¯æŒ
3. å®ç°Agentè§„åˆ’èƒ½åŠ›
4. æ·»åŠ å®‰å…¨è¿‡æ»¤
5. æ”¯æŒæ’ä»¶ç³»ç»Ÿ

ğŸ’¡ ä½¿ç”¨æç¤º:

1. è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY ä½¿ç”¨çœŸå®API
2. å¯ä»¥æ‰©å±•å·¥å…·ç³»ç»Ÿæ·»åŠ æ›´å¤šåŠŸèƒ½
3. æ³¨æ„APIè°ƒç”¨çš„æˆæœ¬æ§åˆ¶
4. å®ç°é€‚å½“çš„é”™è¯¯é‡è¯•æœºåˆ¶
"""